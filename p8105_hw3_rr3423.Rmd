---
title: "p8105_hw3_rr3423.Rmd"
author: "Ragyie Rawal"
date: "10/13/2021"
output: github_document
---

```{r setup, include = FALSE}
library(tidyverse)
library(p8105.datasets)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


## PROBLEM 1

### Loading Instacart dataset from p8105.datasets 

```{r load_instacart}
data("instacart")
```

### Dataset exploration 

```{r data_exploration_instacart}
rows_instacart = 
  instacart %>% 
  nrow() 

cols_instacart =
  instacart %>%
  ncol()

names_instacart =
  instacart %>%
  names()
```

The number of **rows** in the instacart dataset are **`r rows_instacart`**. The number of **columns** in the instacart dataset are **`r cols_instacart`**. The **key variables** in the instacart dataset are **`r names_instacart`**. The dataset contains 1,384,617 observations, and each row in the dataset represents a product from an instacart order. The dataset gives information on the order, such as providing an order id, the order day of the week, the order hour of the day, the product name, and the aisle and department names. 

### Aisles 

How many aisles are there, and which aisles are the most items ordered from? 

```{r aisles_instacart}
instacart %>% 
  group_by(aisle) %>% 
  summarize(item_count = n()) %>% 
  arrange(desc(item_count))
```

There are 134 aisles in the instacart dataset. The top 3 aisles that the most items are ordered from are: "fresh vegetables", "fresh fruits", and "packaged vegetables fruits". 

### Constructing a plot of the number of items ordered in each aisle (more than 10000 items ordered)

```{r aisles_plot_instacart}
instacart %>% 
  group_by(aisle) %>% 
  summarize(item_count = n()) %>% 
  filter(item_count > 10000) %>% 
  ggplot(aes(x = reorder(aisle, item_count), y = item_count)) +
  geom_bar(stat = "identity") +
  coord_flip() + 
  labs(
    title = "Number of items ordered in each aisle (>10000 items)",
    x = "Aisle name",
    y = "Items ordered",
    caption = "Data from the instacart dataset"
  ) + 
  theme(axis.text.y = element_text(size = 7))
```

This plot shows that the top 3 aisles that the most items are ordered from in descending order are: "fresh vegetables", "fresh fruits", and "packaged vegetables fruits". The "fresh vegetables" aisle has 150609 items ordered, the "fresh fruits" aisle has 150473 items ordered, and the "packaged vegetables fruits" aisle has 78493 items ordered.  

### Constructing a table of three most popular items in each of the aisles "baking ingredients", "dog food care", "packaged vegetables fruits"

```{r popular_items_table, message = FALSE, warning = FALSE}
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle, product_name) %>% 
  summarize(item_count = n()) %>% 
  filter(min_rank(desc(item_count)) < 4) %>% 
  arrange(desc(item_count), .by_group = TRUE) %>% 
  knitr::kable(caption = "**Table 1: Three most popular items in specific aisles**")
```

This table shows that the top three popular items in the "baking ingredients" aisle are: Light Brown Sugar with 499 items ordered, Pure Baking Soda with 387 times ordered, and Cane Sugar with 336 times ordered. The top three popular items in the "dog food care" aisle are: Snack Sticks Chicken & Rice Recipe Dog Treats with 30 times ordered, Organix Chicken & Brown Rice Recipe with 28 times ordered, and Small Dog Biscuits with 26 times ordered. The top three popular items in the "packaged vegetables fruits" aisle are: Organic Baby Spinach with 9784 times ordered, Organic Raspberries with 5546 times ordered, and Organic Blueberries with 4966 times ordered. 

### Constructing a 2x7 table of mean hour of day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week 

```{r mean_hour_table, message = FALSE, warning = FALSE}
instacart %>% 
  mutate(
    order_dow = recode(order_dow,
                       "0" = "Sunday",
                       "1" = "Monday",
                       "2" = "Tuesday",
                       "3" = "Wednesday",
                       "4" = "Thursday",
                       "5" = "Friday",
                       "6" = "Saturday")
  ) %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(mean_hour = mean(order_hour_of_day, na.rm = TRUE)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  ) %>%  
  select(product_name, Monday, Tuesday, Wednesday, Thursday, Friday, Saturday, Sunday, everything()) %>% 
  knitr::kable(
    digits = 1,
    caption = "**Table 2: Mean hour of day for pink lady apples and coffee ice cream orders**"
  )
```

Based on this table, it appears that **pink lady apples** are ordered earlier in the day on most days (Monday, Tuesday, Wednesday, Thursday, Saturday, Sunday) when compared to **coffee ice cream**. However, on Fridays, **coffee ice cream** is ordered slightly earlier than **pink lady apples**. In addition, **coffee ice cream** is ordered earliest in the day on Fridays when compared to the rest of the week. **Pink lady apples** are ordered earliest in the day on Mondays. **Coffee ice cream** is ordered latest in the day on Tuesdays. **Pink lady apples** are ordered latest in the day on Wednesdays. 

## PROBLEM 2 

### Loading BRFSS dataset from p8105.datasets 

```{r load_BRFSS}
data("brfss_smart2010")
```

### Data cleaning for BRFSS dataset 

```{r data_cleaning_BRFSS}
brfss_df = 
  brfss_smart2010 %>% 
  janitor::clean_names() %>%
  filter(topic %in% c("Overall Health")) %>% 
  filter(response %in% c("Excellent", "Very good", "Good", "Fair", "Poor")) %>% 
  mutate(response = forcats::fct_relevel(response, "Poor", "Fair", "Good", "Very good", "Excellent"))
```

### In 2002, which states were observed at 7 or more locations? 

```{r 2002_states_observed}
brfss_df %>% 
  filter(year == "2002") %>% 
  group_by(locationabbr) %>% 
  summarize(location_count = n_distinct(locationdesc)) %>% 
  filter(location_count >= 7)
```

In 2002, the following six states were observed at 7 or more locations: CT, FL, MA, NC, NJ, PA. 

### In 2010, which states were observed at 7 or more locations? 

```{r 2010_states_observed}
brfss_df %>% 
  filter(year == "2010") %>% 
  group_by(locationabbr) %>% 
  summarize(location_count = n_distinct(locationdesc)) %>% 
  filter(location_count >= 7)
```

In 2010, the following fourteen states were observed at 7 or more locations: CA, CO, FL, MA, MD, NC, NE, NJ, NY, OH, PA, SC, TX, WA. 

### Constructing a dataset and spaghetti plot limited to Excellent responses which contains year, state, and a variable that averages the data_value across locations within a state.

```{r constructing_dataset, message = FALSE, warning = FALSE}
# constructing dataset and making spaghetti plot
brfss_df %>% 
  filter(response %in% "Excellent") %>% 
  group_by(year, locationabbr) %>% 
  summarize(mean_data_value = mean(data_value, na.rm = TRUE)) %>% 
  ggplot(aes(x = year, y = mean_data_value, color = locationabbr)) + 
  geom_line(aes(group = locationabbr)) +
  labs(
    title = "Average data value over time across locations within a state",
    x = "Year",
    y = "Average data value",
    caption = "Data from the BRFSS dataset"
  ) + 
  theme(legend.position = "right")
```

Looking at this spaghetti plot, it seems that the average data_value across locations within a state seem to fluctuate from year to year in many states between 2002 and 2010.

### Making a two-panel plot showing the distribution of data_value for responses among locations in NY State for the years 2006 and 2010 

```{r two_panel_plot}
brfss_df %>% 
  filter(
    year %in% c("2006", "2010"),
    locationabbr %in% c("NY")
  ) %>% 
  ggplot(aes(x = data_value, y = response, color = locationdesc)) + 
  geom_point() +
  facet_grid(. ~ year) + 
  labs(
    title = "Data value distribution for responses in NY in 2006 and 2010",
    x = "Data value",
    y = "Response",
    caption = "Data from the BRFSS dataset"
  )
```


## PROBLEM 3 

### Loading accelerometer csv dataset 

```{r loading_accel_data}
accel_df = 
  read_csv("data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "activity_minute",
    names_prefix = "activity_",
    values_to = "activity_count"
  ) %>% 
  mutate(
    weekday_vs_weekend = case_when(day == "Monday" ~ "weekday",
                                   day == "Tuesday" ~ "weekday",
                                   day == "Wednesday" ~ "weekday",
                                   day == "Thursday" ~ "weekday",
                                   day == "Friday" ~ "weekday",
                                   day == "Saturday" ~ "weekend",
                                   day == "Sunday" ~ "weekend"),
    activity_minute = as.integer(activity_minute),
    week = as.integer(week),
    day_id = as.integer(day_id),
    day = factor(day, levels = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"))
  ) %>% 
  select(week, day_id, day, weekday_vs_weekend, everything())
```

### Describing the accelerometer dataset 

```{r}
variables_accel = 
  accel_df %>% 
  names()

dim_accel = 
  accel_df %>% 
  dim()

rows_accel = 
  accel_df %>% 
  nrow()

cols_accel = 
  accel_df %>% 
  ncol()
```

This tidied accelerometer dataset represents five weeks of accelerometer data for one individual. This dataset contains a variable for the activity minute, which represents each minute of a 24-hour day starting at midnight for the activity count data. This tidied dataset also contains a weekday vs. weekend variable which determines if the day of the week being represented is a weekday or a weekend day. 

The **key variables** in this tidied dataset are **`r variables_accel`**. The **dimensions** of this tidied dataset are **`r dim_accel`**. The **number of rows** in this tidied dataset are **`r rows_accel`**. The **number of columns** in this tidied dataset are **`r cols_accel`**. 

### Creating a table showing total activity over each day

```{r minutes_activity_table}
accel_df %>% 
  group_by(day) %>% 
  summarize(total_activity = sum(activity_count, na.rm = TRUE)) %>% 
  knitr::kable(digits = 1)
```

For this problem, show total minutes for each of the separate 35 days 

### Creating a single-panel plot showing the 24-hour activity time course in minutes for each day 

```{r activity_time_plot}
accel_df %>% 
  group_by(day, activity_minute) %>% 
  ggplot(aes(x = activity_minute, y = activity_count, color = day)) + 
  geom_point(alpha = 0.5) + 
  labs(
    title = "24-hour activity time course for each day",
    x = "Minutes in the day (hr)",
    y = "Activity count",
    caption = "Data from Columbia University Medical Center"
  ) + 
  theme(legend.position = "right") + 
  scale_x_continuous(
    breaks = c(0, 240, 480, 720, 960, 1200, 1440))
```

